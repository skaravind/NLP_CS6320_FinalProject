{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"nlp_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "df = df.reset_index(drop=True)\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-zA-Z#+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub(' ', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df['body'] = df['body'].apply(clean_text)\n",
    "df['body'] = df['body'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>author</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>answering question criticism individual referr...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1584474347</td>\n",
       "      <td>lostdoty13</td>\n",
       "      <td>t3_fkb1jo</td>\n",
       "      <td>t1_fkrog8a</td>\n",
       "      <td>{'anger': True, 'anticipation': False, 'disgus...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>going start today discussion thread personal o...</td>\n",
       "      <td>CoronavirusCA</td>\n",
       "      <td>1583695737</td>\n",
       "      <td>ErikCavey</td>\n",
       "      <td>t3_ffhe1g</td>\n",
       "      <td>t3_ffhe1g</td>\n",
       "      <td>{'anger': True, 'anticipation': True, 'disgust...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announcing  self quarantined paints picture ma...</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>1582324871</td>\n",
       "      <td>jimkurth81</td>\n",
       "      <td>t3_f76ab0</td>\n",
       "      <td>t1_fiaxs2j</td>\n",
       "      <td>{'anger': True, 'anticipation': True, 'disgust...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>likewise sorry offended actually immunocomprom...</td>\n",
       "      <td>China_Flu</td>\n",
       "      <td>1583140191</td>\n",
       "      <td>DickGrimes79</td>\n",
       "      <td>t3_fc8ar8</td>\n",
       "      <td>t1_fj9aaqt</td>\n",
       "      <td>{'anger': True, 'anticipation': False, 'disgus...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people infected experience high fever cough sh...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1583741759</td>\n",
       "      <td>Fresherty</td>\n",
       "      <td>t3_ffebea</td>\n",
       "      <td>t1_fjzd331</td>\n",
       "      <td>{'anger': False, 'anticipation': False, 'disgu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body      subreddit  \\\n",
       "0  answering question criticism individual referr...      worldnews   \n",
       "1  going start today discussion thread personal o...  CoronavirusCA   \n",
       "2  announcing  self quarantined paints picture ma...    Coronavirus   \n",
       "3  likewise sorry offended actually immunocomprom...      China_Flu   \n",
       "4  people infected experience high fever cough sh...      worldnews   \n",
       "\n",
       "  created_utc        author    link_id   parent_id  \\\n",
       "0  1584474347    lostdoty13  t3_fkb1jo  t1_fkrog8a   \n",
       "1  1583695737     ErikCavey  t3_ffhe1g   t3_ffhe1g   \n",
       "2  1582324871    jimkurth81  t3_f76ab0  t1_fiaxs2j   \n",
       "3  1583140191  DickGrimes79  t3_fc8ar8  t1_fj9aaqt   \n",
       "4  1583741759     Fresherty  t3_ffebea  t1_fjzd331   \n",
       "\n",
       "                                             emotion complete  \n",
       "0  {'anger': True, 'anticipation': False, 'disgus...     True  \n",
       "1  {'anger': True, 'anticipation': True, 'disgust...    False  \n",
       "2  {'anger': True, 'anticipation': True, 'disgust...    False  \n",
       "3  {'anger': True, 'anticipation': False, 'disgus...    False  \n",
       "4  {'anger': False, 'anticipation': False, 'disgu...    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "y = defaultdict(list)\n",
    "for i, post in enumerate(df['emotion']):\n",
    "    for emotion in post:\n",
    "        if df['emotion'][i][emotion]:\n",
    "            y[emotion].append(1)\n",
    "        else:\n",
    "            y[emotion].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1493 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0         1             0        1     0    0     0         0          1   \n",
       "1         1             1        1     1    0     0         0          1   \n",
       "2         1             1        1     1    0     0         0          1   \n",
       "3         1             0        1     1    0     0         0          1   \n",
       "4         0             0        0     0    0     0         0          0   \n",
       "...     ...           ...      ...   ...  ...   ...       ...        ...   \n",
       "1488      1             0        1     1    0     0         0          1   \n",
       "1489      1             0        1     1    0     0         0          0   \n",
       "1490      0             1        0     1    0     0         1          0   \n",
       "1491      0             1        0     1    0     0         0          0   \n",
       "1492      0             0        0     0    0     0         0          0   \n",
       "\n",
       "      sadness  surprise  trust  neutral  \n",
       "0           0         0      0        0  \n",
       "1           0         0      0        0  \n",
       "2           0         0      0        0  \n",
       "3           0         0      0        0  \n",
       "4           0         0      0        1  \n",
       "...       ...       ...    ...      ...  \n",
       "1488        1         0      0        0  \n",
       "1489        1         0      0        0  \n",
       "1490        0         0      1        0  \n",
       "1491        1         0      0        0  \n",
       "1492        0         0      0        0  \n",
       "\n",
       "[1493 rows x 12 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28327 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each post\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['body'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (1493, 250)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = tokenizer.texts_to_sequences(df['body'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of labels: (1493, 12)\n"
     ]
    }
   ],
   "source": [
    "y = labels.values\n",
    "print('Shape of labels:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddits = pd.get_dummies(df[\"subreddit\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((X, subreddits), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1208 samples, validate on 135 samples\n",
      "Epoch 1/10\n",
      "1208/1208 [==============================] - 14s 11ms/step - loss: 0.6522 - acc: 0.6689 - val_loss: 0.5708 - val_acc: 0.6963\n",
      "Epoch 2/10\n",
      "1208/1208 [==============================] - 9s 7ms/step - loss: 0.5447 - acc: 0.7183 - val_loss: 0.5417 - val_acc: 0.6944\n",
      "Epoch 3/10\n",
      "1208/1208 [==============================] - 10s 9ms/step - loss: 0.5391 - acc: 0.7191 - val_loss: 0.5398 - val_acc: 0.6963\n",
      "Epoch 4/10\n",
      "1208/1208 [==============================] - 9s 7ms/step - loss: 0.5364 - acc: 0.7184 - val_loss: 0.5421 - val_acc: 0.6963\n",
      "Epoch 5/10\n",
      "1208/1208 [==============================] - 9s 7ms/step - loss: 0.5315 - acc: 0.7254 - val_loss: 0.5431 - val_acc: 0.6944\n",
      "Epoch 6/10\n",
      "1208/1208 [==============================] - 10s 8ms/step - loss: 0.5168 - acc: 0.7394 - val_loss: 0.5294 - val_acc: 0.7191\n",
      "Epoch 7/10\n",
      "1208/1208 [==============================] - 8s 7ms/step - loss: 0.4795 - acc: 0.7792 - val_loss: 0.5278 - val_acc: 0.7296\n",
      "Epoch 8/10\n",
      "1208/1208 [==============================] - 8s 7ms/step - loss: 0.4431 - acc: 0.7944 - val_loss: 0.5451 - val_acc: 0.7216\n",
      "Epoch 9/10\n",
      "1208/1208 [==============================] - 8s 7ms/step - loss: 0.4157 - acc: 0.8137 - val_loss: 0.5414 - val_acc: 0.7247\n",
      "Epoch 10/10\n",
      "1208/1208 [==============================] - 8s 7ms/step - loss: 0.3735 - acc: 0.8435 - val_loss: 0.5485 - val_acc: 0.7352\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import KLD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(12, activation='sigmoid'))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 2ms/step\n",
      "Test set\n",
      "  Loss: 0.550\n",
      "  Accuracy: 0.747\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(x_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = tokenizer.texts_to_sequences([\"I love\"])\n",
    "check = pad_sequences(check, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 250)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01627871, 0.13510546, 0.03018257, 0.0596163 , 0.06014183,\n",
       "        0.0330528 , 0.16225225, 0.04297176, 0.03085311, 0.03399587,\n",
       "        0.11988373, 0.59112555]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_anger = labels['disgust'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_anger, test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression(C=0.1,random_state=0).fit(x_train, y_train)\n",
    "lr_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "sc = MinMaxScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5466666666666666"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(max_depth = 30, n_estimators = 200)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03687913, 0.02323363, 0.01926585, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.26039224, 0.07427896, 0.0873993 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.02568749, 0.03734931, 0.96747226, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
